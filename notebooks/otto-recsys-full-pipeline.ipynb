{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d717427e",
   "metadata": {
    "_cell_guid": "1b756def-d852-4994-aed8-25f06c7fcef5",
    "_uuid": "6b39da49-a2df-462b-96fd-ab41ad74959d",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.008622,
     "end_time": "2025-12-02T02:27:44.877729",
     "exception": false,
     "start_time": "2025-12-02T02:27:44.869107",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Otto RecSys - Candidate ReRank Model - Use source code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9915d51e",
   "metadata": {
    "_cell_guid": "a22bf930-8cf4-4893-8d2f-0d7e50cf34aa",
    "_uuid": "e8cfb350-2c98-43ea-add0-0f94a9d1a134",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.007147,
     "end_time": "2025-12-02T02:27:44.892623",
     "exception": false,
     "start_time": "2025-12-02T02:27:44.885476",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7a53e3c",
   "metadata": {
    "_cell_guid": "52dd34df-ac5a-434a-bc56-7f47c0ad2515",
    "_uuid": "f1e7225e-db97-40e2-b6da-95dda9f5ca17",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-02T02:27:44.907876Z",
     "iopub.status.busy": "2025-12-02T02:27:44.907556Z",
     "iopub.status.idle": "2025-12-02T02:27:46.343984Z",
     "shell.execute_reply": "2025-12-02T02:27:46.342855Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.446206,
     "end_time": "2025-12-02T02:27:46.345803",
     "exception": false,
     "start_time": "2025-12-02T02:27:44.899597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'otto-rec-sys'...\r\n",
      "remote: Enumerating objects: 95, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (95/95), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (65/65), done.\u001b[K\r\n",
      "remote: Total 95 (delta 43), reused 76 (delta 24), pack-reused 0 (from 0)\u001b[K\r\n",
      "Receiving objects: 100% (95/95), 1.64 MiB | 18.67 MiB/s, done.\r\n",
      "Resolving deltas: 100% (43/43), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/triet4p/otto-rec-sys.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddb7e283",
   "metadata": {
    "_cell_guid": "bbe9a6dd-5931-42e9-934c-9145296c05f2",
    "_uuid": "b7fce74c-2d8e-45b9-adc9-ce96f1d60ddc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-02T02:27:46.363940Z",
     "iopub.status.busy": "2025-12-02T02:27:46.363206Z",
     "iopub.status.idle": "2025-12-02T02:27:46.506525Z",
     "shell.execute_reply": "2025-12-02T02:27:46.505339Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.153932,
     "end_time": "2025-12-02T02:27:46.508445",
     "exception": false,
     "start_time": "2025-12-02T02:27:46.354513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/otto-rec-sys\n",
      "Note: switching to '33986ff48aa765cb612d02b94565c7818c0fbfe6'.\r\n",
      "\r\n",
      "You are in 'detached HEAD' state. You can look around, make experimental\r\n",
      "changes and commit them, and you can discard any commits you make in this\r\n",
      "state without impacting any branches by switching back to a branch.\r\n",
      "\r\n",
      "If you want to create a new branch to retain commits you create, you may\r\n",
      "do so (now or later) by using -c with the switch command. Example:\r\n",
      "\r\n",
      "  git switch -c <new-branch-name>\r\n",
      "\r\n",
      "Or undo this operation with:\r\n",
      "\r\n",
      "  git switch -\r\n",
      "\r\n",
      "Turn off this advice by setting config variable advice.detachedHead to false\r\n",
      "\r\n",
      "HEAD is now at 33986ff Update training.py\r\n"
     ]
    }
   ],
   "source": [
    "%cd otto-rec-sys\n",
    "!git checkout 33986ff48aa765cb612d02b94565c7818c0fbfe6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8151b388",
   "metadata": {
    "_cell_guid": "c28e1ed1-9259-4c29-8d5c-748969169dd1",
    "_uuid": "b5d716a3-d850-41e8-a0b9-f924dc20196a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-02T02:27:46.526024Z",
     "iopub.status.busy": "2025-12-02T02:27:46.525120Z",
     "iopub.status.idle": "2025-12-02T02:27:46.530080Z",
     "shell.execute_reply": "2025-12-02T02:27:46.529171Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.015339,
     "end_time": "2025-12-02T02:27:46.531652",
     "exception": false,
     "start_time": "2025-12-02T02:27:46.516313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/kaggle/working/otto-rec-sys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9efc2a80",
   "metadata": {
    "_cell_guid": "b0b067ab-8b6b-4ba1-a0ca-24d5c2f33d92",
    "_uuid": "da3bc7a4-6ddd-4c83-a484-5e1de2485a1f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-02T02:27:46.548219Z",
     "iopub.status.busy": "2025-12-02T02:27:46.547940Z",
     "iopub.status.idle": "2025-12-02T02:28:27.024723Z",
     "shell.execute_reply": "2025-12-02T02:28:27.023666Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 40.493162,
     "end_time": "2025-12-02T02:28:27.032619",
     "exception": false,
     "start_time": "2025-12-02T02:27:46.539457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.4 s, sys: 29.3 s, total: 59.8 s\n",
      "Wall time: 40.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from src.core.utils import load_raw_data_parquet\n",
    "# Load train parquet\n",
    "\n",
    "train_df = load_raw_data_parquet('/kaggle/input/otto-chunk-data-inparquet-format/train_parquet/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edc77940",
   "metadata": {
    "_cell_guid": "c6ff3cfc-4bf2-4311-ba52-91763c7cff68",
    "_uuid": "409222fc-e99f-4976-af41-6ed0287648f2",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-02T02:28:27.049605Z",
     "iopub.status.busy": "2025-12-02T02:28:27.049262Z",
     "iopub.status.idle": "2025-12-02T02:28:49.451336Z",
     "shell.execute_reply": "2025-12-02T02:28:49.450315Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 22.412736,
     "end_time": "2025-12-02T02:28:49.452967",
     "exception": false,
     "start_time": "2025-12-02T02:28:27.040231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.7 s, sys: 7.3 s, total: 26 s\n",
      "Wall time: 22.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from src.candidate_generation.loader import load_covisit_matrix\n",
    "MATRIX_BASE_PATH = '/kaggle/input/otto-precal-covisit-matrices/submission/train/'\n",
    "\n",
    "df_clicks_train = load_covisit_matrix(MATRIX_BASE_PATH + 'top_*_clicks_*.pqt', 'clicks', 20)\n",
    "df_buys_train = load_covisit_matrix(MATRIX_BASE_PATH + 'top_*_carts_orders_*.pqt', 'buys', 15)\n",
    "df_buy2buy_train = load_covisit_matrix(MATRIX_BASE_PATH + 'top_*_buy2buy_*.pqt', 'buy2buy', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fa99524",
   "metadata": {
    "_cell_guid": "e87ad537-3fc1-4bbc-8f7d-c58b5d9a6674",
    "_uuid": "0d00e652-278d-4ba3-ab04-5b7edb3d9c57",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-02T02:28:49.469902Z",
     "iopub.status.busy": "2025-12-02T02:28:49.469618Z",
     "iopub.status.idle": "2025-12-02T02:29:27.313507Z",
     "shell.execute_reply": "2025-12-02T02:29:27.312369Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 37.854462,
     "end_time": "2025-12-02T02:29:27.315477",
     "exception": false,
     "start_time": "2025-12-02T02:28:49.461015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.pipeline.preprocess import sample_train\n",
    "TRAIN_SESSION_SAMPLE_RATE = 0.18 # Lấy 40% số session\n",
    "\n",
    "sampled_train_dfs = []\n",
    "seeds = [42,43,44]\n",
    "\n",
    "for i in range(len(seeds)):\n",
    "    sampled_train_dfs.append(sample_train(train_df,\n",
    "                                          TRAIN_SESSION_SAMPLE_RATE,\n",
    "                                          seed=seeds[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e0c858d",
   "metadata": {
    "_cell_guid": "8e90eb3b-7c86-4995-a785-e279ed9a739a",
    "_uuid": "f3bb88c9-6b72-4ff6-a6cd-5d8e80fe7062",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-02T02:29:27.332797Z",
     "iopub.status.busy": "2025-12-02T02:29:27.332154Z",
     "iopub.status.idle": "2025-12-02T02:29:45.392331Z",
     "shell.execute_reply": "2025-12-02T02:29:45.391462Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 18.070591,
     "end_time": "2025-12-02T02:29:45.394083",
     "exception": false,
     "start_time": "2025-12-02T02:29:27.323492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History and Labels for training have been created.\n",
      "History and Labels for training have been created.\n",
      "History and Labels for training have been created.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from src.pipeline.preprocess import get_history_and_label_df\n",
    "history_dfs = []\n",
    "history_source_dfs = []\n",
    "truth_label_dfs = []\n",
    "\n",
    "for i in range(len(seeds)):\n",
    "    history_df, truth_label_df, history_source_df = get_history_and_label_df(sampled_train_dfs[i])\n",
    "    history_dfs.append(history_df)\n",
    "    truth_label_dfs.append(truth_label_df)\n",
    "    history_source_dfs.append(history_source_df)\n",
    "\n",
    "    del history_df, truth_label_df\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afeced66",
   "metadata": {
    "_cell_guid": "4728cf0c-b9d8-4800-9628-6c79343022bb",
    "_uuid": "ec695fbf-209a-4120-a956-e22a5290b74c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-02T02:29:45.411374Z",
     "iopub.status.busy": "2025-12-02T02:29:45.411013Z",
     "iopub.status.idle": "2025-12-02T02:29:55.230682Z",
     "shell.execute_reply": "2025-12-02T02:29:55.229706Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 9.830424,
     "end_time": "2025-12-02T02:29:55.232466",
     "exception": false,
     "start_time": "2025-12-02T02:29:45.402042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.pipeline.preprocess import get_popular_items_df\n",
    "\n",
    "popular_items_dfs = []\n",
    "for i in range(len(seeds)):\n",
    "    popular_items_dfs.append(get_popular_items_df(sampled_train_dfs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8328c8f",
   "metadata": {
    "_cell_guid": "0fc96977-f1ab-42ed-acfd-ed790ac0fe60",
    "_uuid": "caad5d34-90cb-44c8-9eb1-efb069030657",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-02T02:29:55.251573Z",
     "iopub.status.busy": "2025-12-02T02:29:55.251208Z",
     "iopub.status.idle": "2025-12-02T02:30:14.897534Z",
     "shell.execute_reply": "2025-12-02T02:30:14.896486Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 19.657837,
     "end_time": "2025-12-02T02:30:14.899314",
     "exception": false,
     "start_time": "2025-12-02T02:29:55.241477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.pipeline.preprocess import pre_compute_item_popularity\n",
    "item_popularity_dfs = []\n",
    "for i in range(len(seeds)):\n",
    "    item_popularity_dfs.append(pre_compute_item_popularity(sampled_train_dfs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c702ea4",
   "metadata": {
    "_cell_guid": "2459a3de-23f5-468c-9289-fa9416c414e3",
    "_uuid": "dbbe1d94-19fd-4bc8-bd62-98130dfb8e2a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-02T02:30:14.916217Z",
     "iopub.status.busy": "2025-12-02T02:30:14.915923Z",
     "iopub.status.idle": "2025-12-02T02:42:27.491977Z",
     "shell.execute_reply": "2025-12-02T02:42:27.490757Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 732.586611,
     "end_time": "2025-12-02T02:42:27.493964",
     "exception": false,
     "start_time": "2025-12-02T02:30:14.907353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing 547624 sessions in 21 chunks ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [03:46<00:00, 10.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing 548829 sessions in 21 chunks ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [03:48<00:00, 10.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing 548386 sessions in 21 chunks ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [04:36<00:00, 13.18s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "from src.pipeline.preprocess import process_chunk\n",
    "\n",
    "N_CHUNKS = 20\n",
    "for i in range(len(seeds)):\n",
    "    history_df = history_dfs[i]\n",
    "    popular_items_df = popular_items_dfs[i]\n",
    "    all_sessions = history_df['session'].unique().to_list()\n",
    "    chunk_size = len(all_sessions) // N_CHUNKS\n",
    "\n",
    "    TEMP_CHUNK_PATH = f'/kaggle/working/temp_candidate_chunks/sample_{i}/' # Thư mục để lưu các file tạm\n",
    "    \n",
    "    os.makedirs(TEMP_CHUNK_PATH, exist_ok=True)\n",
    "    \n",
    "    print(f\"\\n--- Processing {len(all_sessions)} sessions in {N_CHUNKS+1} chunks ---\")\n",
    "    for i in tqdm(range(N_CHUNKS + 1)):\n",
    "        start = i * chunk_size\n",
    "        end = (i + 1) * chunk_size\n",
    "        if start >= len(all_sessions):\n",
    "            break\n",
    "        \n",
    "        session_chunk_ids = all_sessions[start:end]\n",
    "        history_chunk = history_df.filter(pl.col('session').is_in(session_chunk_ids))\n",
    "        \n",
    "        # Gọi hàm xử lý cho chunk\n",
    "        chunk_result = process_chunk(history_chunk, popular_items_df,\n",
    "                                     df_clicks_train, df_buys_train, df_buy2buy_train)\n",
    "        # Thêm đặc trưng cuối cùng cho nguồn popular\n",
    "        chunk_result = chunk_result.with_columns(\n",
    "            pl.col('candidate_aid').is_in(popular_items_df['candidate_aid']).cast(pl.UInt8).alias('source_popular')\n",
    "        )\n",
    "        # --- THAY ĐỔI QUAN TRỌNG: LƯU RA FILE THAY VÌ APPEND VÀO LIST ---\n",
    "        chunk_result.write_parquet(TEMP_CHUNK_PATH + f'candidates_chunk_{i}.pqt')\n",
    "        \n",
    "        # Dọn dẹp bộ nhớ\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4057fb57",
   "metadata": {
    "_cell_guid": "7da745a6-f0a9-4cd7-b3b7-55139b420df8",
    "_uuid": "46147a49-36c7-4305-b1d9-048ca53e83d7",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-02T02:42:27.519368Z",
     "iopub.status.busy": "2025-12-02T02:42:27.519026Z",
     "iopub.status.idle": "2025-12-02T02:42:27.985501Z",
     "shell.execute_reply": "2025-12-02T02:42:27.984596Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.480815,
     "end_time": "2025-12-02T02:42:27.987062",
     "exception": false,
     "start_time": "2025-12-02T02:42:27.506247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del df_clicks_train, df_buys_train, df_buy2buy_train, popular_items_dfs, sampled_train_dfs\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4713e203",
   "metadata": {
    "_cell_guid": "19f5b455-43ef-4a2e-85ff-484e36c63b0c",
    "_uuid": "f5bc6bd4-9833-4d92-85b4-111fdcf4fb97",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-02T02:42:28.011834Z",
     "iopub.status.busy": "2025-12-02T02:42:28.011512Z",
     "iopub.status.idle": "2025-12-02T02:42:28.016517Z",
     "shell.execute_reply": "2025-12-02T02:42:28.015513Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.019677,
     "end_time": "2025-12-02T02:42:28.018215",
     "exception": false,
     "start_time": "2025-12-02T02:42:27.998538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8e59d3",
   "metadata": {
    "_cell_guid": "5afc297c-1d29-4eb3-82c5-bcc78d256c2f",
    "_uuid": "47157c3f-cf13-4f2b-a6bb-78b9088afde5",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.011391,
     "end_time": "2025-12-02T02:42:28.041128",
     "exception": false,
     "start_time": "2025-12-02T02:42:28.029737",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cc0635c",
   "metadata": {
    "_cell_guid": "b742e41c-8e63-4adb-a6de-4a7d043c7f06",
    "_uuid": "5af2d0fc-1f04-4576-9a11-bb2d97130c4e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-02T02:42:28.066195Z",
     "iopub.status.busy": "2025-12-02T02:42:28.065009Z",
     "iopub.status.idle": "2025-12-02T02:42:28.070547Z",
     "shell.execute_reply": "2025-12-02T02:42:28.069565Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.019727,
     "end_time": "2025-12-02T02:42:28.072103",
     "exception": false,
     "start_time": "2025-12-02T02:42:28.052376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4. Tạo ra 3 bộ dữ liệu huấn luyện riêng biệt\n",
    "# Định nghĩa các siêu tham số cho việc lấy mẫu\n",
    "TARGET_RATIOS = {'clicks': 10, 'carts': 20, 'orders': 30}\n",
    "POS_RATE = {'clicks': 0.5, 'carts': 1.0, 'orders': 1.0}\n",
    "POPULAR_FRACTION = 0.5 # 50% mẫu âm sẽ là \"khó\", 50% là ngẫu nhiên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6b398cf",
   "metadata": {
    "_cell_guid": "e9fed50f-7a45-4816-9b9e-5af63d19d931",
    "_uuid": "ecdb6be3-6f0b-4475-9feb-51626a6a49e4",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-02T02:42:28.098591Z",
     "iopub.status.busy": "2025-12-02T02:42:28.097517Z",
     "iopub.status.idle": "2025-12-02T02:53:57.795050Z",
     "shell.execute_reply": "2025-12-02T02:53:57.791531Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 689.721321,
     "end_time": "2025-12-02T02:53:57.805533",
     "exception": false,
     "start_time": "2025-12-02T02:42:28.084212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Creating training set for 'clicks'  ---\n",
      "0\n",
      "Collecting positive samples for '0'...\n",
      "Collecting all negative samples for '0'...\n",
      "Positives: 318297. Total negatives to sample: 3182970 (1591485 popular + 1591485 random)\n",
      "Sampling popular negatives...\n",
      "Sampling random negatives...\n",
      "\n",
      "--- Creating training set for 'carts'  ---\n",
      "1\n",
      "Collecting positive samples for '1'...\n",
      "Collecting all negative samples for '1'...\n",
      "Positives: 94736. Total negatives to sample: 1894720 (947360 popular + 947360 random)\n",
      "Sampling popular negatives...\n",
      "Sampling random negatives...\n",
      "\n",
      "--- Creating training set for 'orders'  ---\n",
      "2\n",
      "Collecting positive samples for '2'...\n",
      "Collecting all negative samples for '2'...\n",
      "Positives: 37009. Total negatives to sample: 1110270 (555135 popular + 555135 random)\n",
      "Sampling popular negatives...\n",
      "Sampling random negatives...\n",
      "\n",
      "--- Creating training set for 'clicks'  ---\n",
      "0\n",
      "Collecting positive samples for '0'...\n",
      "Collecting all negative samples for '0'...\n",
      "Positives: 318053. Total negatives to sample: 3180530 (1590265 popular + 1590265 random)\n",
      "Sampling popular negatives...\n",
      "Sampling random negatives...\n",
      "\n",
      "--- Creating training set for 'carts'  ---\n",
      "1\n",
      "Collecting positive samples for '1'...\n",
      "Collecting all negative samples for '1'...\n",
      "Positives: 94512. Total negatives to sample: 1890240 (945120 popular + 945120 random)\n",
      "Sampling popular negatives...\n",
      "Sampling random negatives...\n",
      "\n",
      "--- Creating training set for 'orders'  ---\n",
      "2\n",
      "Collecting positive samples for '2'...\n",
      "Collecting all negative samples for '2'...\n",
      "Positives: 36862. Total negatives to sample: 1105860 (552930 popular + 552930 random)\n",
      "Sampling popular negatives...\n",
      "Sampling random negatives...\n",
      "\n",
      "--- Creating training set for 'clicks'  ---\n",
      "0\n",
      "Collecting positive samples for '0'...\n",
      "Collecting all negative samples for '0'...\n",
      "Positives: 318222. Total negatives to sample: 3182220 (1591110 popular + 1591110 random)\n",
      "Sampling popular negatives...\n",
      "Sampling random negatives...\n",
      "\n",
      "--- Creating training set for 'carts'  ---\n",
      "1\n",
      "Collecting positive samples for '1'...\n",
      "Collecting all negative samples for '1'...\n",
      "Positives: 95109. Total negatives to sample: 1902180 (951090 popular + 951090 random)\n",
      "Sampling popular negatives...\n",
      "Sampling random negatives...\n",
      "\n",
      "--- Creating training set for 'orders'  ---\n",
      "2\n",
      "Collecting positive samples for '2'...\n",
      "Collecting all negative samples for '2'...\n",
      "Positives: 36896. Total negatives to sample: 1106880 (553440 popular + 553440 random)\n",
      "Sampling popular negatives...\n",
      "Sampling random negatives...\n",
      "CPU times: user 17min 47s, sys: 12min 45s, total: 30min 32s\n",
      "Wall time: 11min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from src.pipeline.training import create_training_set_for_type\n",
    "for i in range(len(seeds)):\n",
    "    TEMP_CHUNK_PATH = f'/kaggle/working/temp_candidate_chunks/sample_{i}/'\n",
    "    lazy_final_df = pl.scan_parquet(TEMP_CHUNK_PATH + 'candidates_chunk_*.pqt')\n",
    "    lazy_final_df = lazy_final_df.fill_null(0)\n",
    "\n",
    "    for pred_type in ['clicks', 'carts', 'orders']:\n",
    "        training_sets = create_training_set_for_type(\n",
    "            lazy_final_df, truth_label_dfs[i], item_popularity_dfs[i], pred_type,\n",
    "            positive_rate = POS_RATE[pred_type],\n",
    "            target_neg_pos_ratio=TARGET_RATIOS[pred_type], popular_fraction=POPULAR_FRACTION\n",
    "        )\n",
    "        training_sets.write_parquet(TEMP_CHUNK_PATH + f'training_set_{pred_type}.pqt')\n",
    "        del training_sets\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14a87774",
   "metadata": {
    "_cell_guid": "43fe84a5-d1a0-4a39-b603-9ec1a98ca041",
    "_uuid": "b0787b83-800d-463b-ace2-4ffe24cb9175",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-02T02:53:57.866579Z",
     "iopub.status.busy": "2025-12-02T02:53:57.866214Z",
     "iopub.status.idle": "2025-12-02T02:53:59.216677Z",
     "shell.execute_reply": "2025-12-02T02:53:59.215704Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.37458,
     "end_time": "2025-12-02T02:53:59.218409",
     "exception": false,
     "start_time": "2025-12-02T02:53:57.843829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- 1. Feature Tĩnh (Item Features) ---\n",
    "def create_time_window_features(feature_source_df: pl.DataFrame, time_window_days: int = None) -> pl.DataFrame:\n",
    "    if time_window_days is not None:\n",
    "        last_ts = feature_source_df['ts'].max()\n",
    "        start_ts = last_ts - (time_window_days * 24 * 60 * 60)\n",
    "        source_df = feature_source_df.filter(pl.col('ts') >= start_ts)\n",
    "        suffix = f'_{time_window_days}d'\n",
    "    else:\n",
    "        source_df = feature_source_df\n",
    "        suffix = '_all'\n",
    "        \n",
    "    item_feats = source_df.group_by('aid').agg([\n",
    "        pl.count().alias(f'item_total_counts{suffix}'),\n",
    "        pl.col('type').filter(pl.col('type') == 0).count().alias(f'item_click_counts{suffix}'),\n",
    "        pl.col('type').filter(pl.col('type') == 1).count().alias(f'item_cart_counts{suffix}'),\n",
    "        pl.col('type').filter(pl.col('type') == 2).count().alias(f'item_order_counts{suffix}'),\n",
    "    ]).rename({'aid': 'candidate_aid'})\n",
    "    \n",
    "    # Tính tỷ lệ chuyển đổi (Smoothing +10 để tránh nhiễu ở item ít tương tác)\n",
    "    item_feats = item_feats.with_columns([\n",
    "        (pl.col(f'item_order_counts{suffix}') / (pl.col(f'item_click_counts{suffix}') + 10)).alias(f'item_buy_ratio{suffix}'),\n",
    "        (pl.col(f'item_cart_counts{suffix}') / (pl.col(f'item_click_counts{suffix}') + 10)).alias(f'item_cart_ratio{suffix}'),\n",
    "    ])\n",
    "    return item_feats\n",
    "\n",
    "# --- 2. Feature Động (Session Context) ---\n",
    "def create_session_context_features(session_context_df: pl.DataFrame) -> tuple[pl.DataFrame, pl.DataFrame, pl.DataFrame]:\n",
    "    \"\"\"\n",
    "    Tính toán tất cả các feature dựa trên context của session.\n",
    "    Trả về: (session_level_features, interaction_level_features, last_item_info)\n",
    "    \"\"\"\n",
    "    # A. Session Level Features\n",
    "    session_feats = session_context_df.group_by('session').agg([\n",
    "        pl.count().alias('session_length'),\n",
    "        pl.col('aid').n_unique().alias('session_unique_aids'),\n",
    "        pl.col('ts').max().alias('session_end_ts'),\n",
    "        (pl.col('ts').max() - pl.col('ts').min()).alias('session_duration'),\n",
    "    ])\n",
    "    \n",
    "    # B. Interaction Level Features (Lặp lại & Thời gian cuối)\n",
    "    interaction_feats = session_context_df.group_by(['session', 'aid']).agg([\n",
    "        pl.count().alias('num_repetitions'),\n",
    "        pl.col('ts').max().alias('last_item_ts')\n",
    "    ]).rename({'aid': 'candidate_aid'})\n",
    "    \n",
    "    # C. Last Item Info (Item cuối cùng user xem)\n",
    "    last_items = session_context_df.sort('ts').group_by('session', maintain_order=True).last()\n",
    "    last_items = last_items.select(['session', 'aid']).rename({'aid': 'last_aid'})\n",
    "    \n",
    "    return session_feats, interaction_feats, last_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "344d01cf",
   "metadata": {
    "_cell_guid": "d19263ba-13ac-4116-9c5e-18f70e4aaad5",
    "_uuid": "fc89d010-624a-4a31-98af-e1c37a5699c7",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-02T02:53:59.248112Z",
     "iopub.status.busy": "2025-12-02T02:53:59.247499Z",
     "iopub.status.idle": "2025-12-02T02:53:59.264805Z",
     "shell.execute_reply": "2025-12-02T02:53:59.263784Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.034526,
     "end_time": "2025-12-02T02:53:59.266611",
     "exception": false,
     "start_time": "2025-12-02T02:53:59.232085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_sorted_rank_features(df: pl.DataFrame, fill_value: int = 999) -> pl.DataFrame:\n",
    "    \"\"\"Tạo feature rank tốt nhất từ tất cả các nguồn.\"\"\"\n",
    "    rank_cols = [col for col in df.columns if col.startswith('rank_')]\n",
    "    if not rank_cols: return df\n",
    "\n",
    "    # Tạo list rank, sort và lấy ra các giá trị min\n",
    "    rank_exprs = [pl.col(c).fill_null(fill_value) for c in rank_cols]\n",
    "    \n",
    "    df = df.with_columns(\n",
    "        pl.concat_list(rank_exprs).list.sort().alias('temp_sorted_ranks')\n",
    "    )\n",
    "    \n",
    "    # Tách ra min_rank_1 (best), min_rank_2 (2nd best)\n",
    "    new_cols = [\n",
    "        pl.col('temp_sorted_ranks').list.get(0).alias('min_rank_1'),\n",
    "        pl.col('temp_sorted_ranks').list.get(1).alias('min_rank_2'),\n",
    "        # Số lượng nguồn gợi ý item này\n",
    "        (pl.col('temp_sorted_ranks').list.eval(pl.element() < fill_value).list.sum()).alias('n_sources_present')\n",
    "    ]\n",
    "    return df.with_columns(new_cols).drop('temp_sorted_ranks')\n",
    "\n",
    "def add_features(df: pl.DataFrame, \n",
    "                 time_window_feats_list: list[pl.DataFrame], # [item_all, item_7d]\n",
    "                 session_feats: pl.DataFrame,\n",
    "                 interaction_feats: pl.DataFrame,\n",
    "                 last_items: pl.DataFrame) -> pl.DataFrame:\n",
    "   \n",
    "    # 1. Join các bảng gốc (Giữ nguyên)\n",
    "    for tw_feat in time_window_feats_list:\n",
    "        df = df.join(tw_feat, on='candidate_aid', how='left')\n",
    "    df = df.join(session_feats, on='session', how='left')\n",
    "    df = df.join(interaction_feats, on=['session', 'candidate_aid'], how='left')\n",
    "    df = df.join(last_items, on='session', how='left')\n",
    "\n",
    "    # --- NHÓM 1: TREND / VELOCITY (Tốc độ tăng trưởng của Item) ---\n",
    "    # So sánh 7 ngày vs All time. \n",
    "    # Logic: Item có tỷ trọng click trong 7 ngày cao bất thường so với lịch sử -> Đang Hot.\n",
    "    \n",
    "    # Giả sử time_window_feats_list[0] là ALL, [1] là 7D\n",
    "    # Các cột sẽ có suffix '_all' và '_7d'\n",
    "    \n",
    "    df = df.with_columns([\n",
    "        # Tỷ lệ click gần đây / click tổng (Cộng 10 để tránh chia 0 và nhiễu)\n",
    "        (pl.col('item_click_counts_7d').fill_null(0) / (pl.col('item_click_counts_all').fill_null(0) + 10)).alias('click_trend_7d_vs_all'),\n",
    "        \n",
    "        # Tỷ lệ order gần đây / order tổng\n",
    "        (pl.col('item_order_counts_7d').fill_null(0) / (pl.col('item_order_counts_all').fill_null(0) + 10)).alias('order_trend_7d_vs_all'),\n",
    "        \n",
    "        # Conversion Rate thay đổi thế nào? (CR 7 ngày - CR All)\n",
    "        (pl.col('item_buy_ratio_7d').fill_null(0) - pl.col('item_buy_ratio_all').fill_null(0)).alias('conversion_trend_diff')\n",
    "    ])\n",
    "\n",
    "    # --- NHÓM 2: CROSS-SOURCE COMPARISON (So sánh giữa các nguồn Co-visit) ---\n",
    "    # Logic: Sự chênh lệch thứ hạng giữa các nguồn nói lên điều gì?\n",
    "    # Ví dụ: Rank Buy2Buy thấp (tốt) nhưng Rank Clicks cao (tệ) -> Item này ít người click nhưng hễ click là mua -> Tiềm năng cao.\n",
    "    \n",
    "    # Fill null rank bằng 999 trước khi tính toán\n",
    "    rank_cols = ['rank_clicks', 'rank_buys', 'rank_buy2buy']\n",
    "    for c in rank_cols:\n",
    "        if c not in df.columns:\n",
    "            df = df.with_columns(pl.lit(999).alias(c))\n",
    "        else:\n",
    "            df = df.with_columns(pl.col(c).fill_null(999))\n",
    "\n",
    "    df = df.with_columns([\n",
    "        # Chênh lệch rank\n",
    "        (pl.col('rank_clicks') - pl.col('rank_buy2buy')).alias('rank_diff_click_buy2buy'),\n",
    "        (pl.col('rank_buys') - pl.col('rank_buy2buy')).alias('rank_diff_buys_buy2buy'),\n",
    "        \n",
    "        # Tổng hợp trọng số (Weighted Sum) - Tạo ra một \"Siêu điểm số\"\n",
    "        (pl.col('wgt_buy2buy').fill_null(0) * 2 + pl.col('wgt_buys').fill_null(0) * 1).alias('combined_buy_weight')\n",
    "    ])\n",
    "\n",
    "    # --- NHÓM 3: CONTEXTUAL RECENCY (Tính gần đây kết hợp ngữ cảnh) ---\n",
    "    # Logic: Recency quan trọng, nhưng Recency của một item \"Hot\" quan trọng hơn Recency của item \"Rác\".\n",
    "    \n",
    "    # Tính Recency cơ bản trước\n",
    "    df = df.with_columns(\n",
    "        (pl.col('session_end_ts') - pl.col('last_item_ts')).fill_null(7*24*3600).alias('recency_score')\n",
    "    )\n",
    "    \n",
    "    # Log Recency để giảm biên độ số (giây -> log giây)\n",
    "    df = df.with_columns(\n",
    "        pl.col('recency_score').log1p().alias('log_recency_score')\n",
    "    )\n",
    "    \n",
    "    # Tương tác: Điểm Co-visit chia cho thời gian (Càng gần càng giá trị)\n",
    "    # Thêm 1 vào log_recency để tránh chia 0\n",
    "    df = df.with_columns([\n",
    "        (pl.col('wgt_buy2buy').fill_null(0) / (pl.col('log_recency_score') + 1)).alias('wgt_buy2buy_decayed'),\n",
    "        (pl.col('wgt_clicks').fill_null(0) / (pl.col('log_recency_score') + 1)).alias('wgt_clicks_decayed')\n",
    "    ])\n",
    "\n",
    "    # --- NHÓM 4: CÁC CỜ (FLAGS) QUAN TRỌNG (Giữ lại từ cũ) ---\n",
    "    df = df.with_columns([\n",
    "        (pl.col('candidate_aid') == pl.col('last_aid')).cast(pl.Int8).fill_null(0).alias('is_last_viewed'),\n",
    "        # Item này có phải là item phổ biến nhất trong session không? (Logic đơn giản: count > 1)\n",
    "        (pl.col('num_repetitions') > 1).cast(pl.Int8).alias('is_repeated_in_session')\n",
    "    ])\n",
    "\n",
    "    # --- Sorted Ranks (Giữ nguyên - rất mạnh) ---\n",
    "    df = add_sorted_rank_features(df)\n",
    "\n",
    "    # Dọn dẹp\n",
    "    df = df.fill_null(0)\n",
    "    cols_to_drop = ['session_end_ts', 'last_item_ts', 'last_aid', 'session_duration', 'first_item_ts'] \n",
    "    df = df.drop([c for c in cols_to_drop if c in df.columns])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6861fc3d",
   "metadata": {
    "_cell_guid": "b7d6379c-3226-4a3c-b3d1-1d584e3d2b95",
    "_uuid": "33e4eb2b-ad7b-4b4f-a115-de84e25d9ce8",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-02T02:53:59.295318Z",
     "iopub.status.busy": "2025-12-02T02:53:59.294851Z",
     "iopub.status.idle": "2025-12-02T02:53:59.305936Z",
     "shell.execute_reply": "2025-12-02T02:53:59.304970Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.027367,
     "end_time": "2025-12-02T02:53:59.307497",
     "exception": false,
     "start_time": "2025-12-02T02:53:59.280130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def select_best_features(df: pl.DataFrame, target_type: str, top_k: int = 60):\n",
    "    \"\"\"\n",
    "    Huấn luyện nhanh 1 model để chọn ra top_k features tốt nhất cho target_type.\n",
    "    \"\"\"\n",
    "    print(f\"  >> Performing Feature Selection for {target_type}...\")\n",
    "    \n",
    "    ignore_cols = ['session', 'candidate_aid', 'label']\n",
    "    feature_cols = [c for c in df.columns if c not in ignore_cols]\n",
    "    \n",
    "    # Sample dữ liệu để chạy nhanh (ví dụ 2 triệu dòng)\n",
    "    if len(df) > 2_000_000:\n",
    "        df_sample = df.sample(n=2_000_000, seed=42)\n",
    "    else:\n",
    "        df_sample = df\n",
    "        \n",
    "    X = df_sample.select(feature_cols).to_numpy()\n",
    "    y = df_sample.select('label').to_numpy().ravel()\n",
    "    groups = df_sample.group_by('session', maintain_order=True).len()['len'].to_numpy()\n",
    "    \n",
    "    # Train model nhẹ\n",
    "    model = lgb.LGBMRanker(\n",
    "        objective=\"lambdarank\", metric=\"map\",\n",
    "        n_estimators=50, learning_rate=0.1, max_depth=5,\n",
    "        importance_type='gain', random_state=42, n_jobs=-1\n",
    "    )\n",
    "    model.fit(X, y, group=groups)\n",
    "    \n",
    "    # Lấy feature importance\n",
    "    imp_df = pl.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'gain': model.feature_importances_\n",
    "    }).sort('gain', descending=True)\n",
    "    \n",
    "    # Chọn top K\n",
    "    best_feats = imp_df.head(top_k)['feature'].to_list()\n",
    "    print(f\"     Selected {len(best_feats)} features. Top 5: {best_feats[:5]}\")\n",
    "    \n",
    "    # (Tùy chọn) In ra các feature bị loại bỏ để kiểm tra\n",
    "    # dropped = [f for f in feature_cols if f not in best_feats]\n",
    "    # print(f\"     Dropped: {dropped[:5]}...\")\n",
    "    \n",
    "    return best_feats\n",
    "\n",
    "def train_final_model(df: pl.DataFrame, features: list, model_type: str):\n",
    "    \"\"\"Huấn luyện model chính thức với danh sách feature đã chọn.\"\"\"\n",
    "    print(f\"  >> Training Final Model for {model_type} with {len(features)} features...\")\n",
    "    \n",
    "    df = df.sort('session')\n",
    "    X = df.select(features).to_numpy()\n",
    "    y = df.select('label').to_numpy().ravel()\n",
    "    groups = df.group_by('session', maintain_order=True).len()['len'].to_numpy()\n",
    "    \n",
    "    model = lgb.LGBMRanker(\n",
    "        objective=\"lambdarank\", metric=\"map\",\n",
    "        n_estimators=500, learning_rate=0.05, num_leaves=32,\n",
    "        subsample=0.8, colsample_bytree=0.7,\n",
    "        random_state=42, n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # --- SỬA LỖI Ở ĐÂY ---\n",
    "    # Thêm eval_set và eval_group\n",
    "    model.fit(\n",
    "        X, \n",
    "        y, \n",
    "        group=groups, \n",
    "        eval_set=[(X, y)],       # Đưa tập train vào làm tập đánh giá\n",
    "        eval_group=[groups],     # Cung cấp thông tin group cho tập đánh giá\n",
    "        callbacks=[lgb.early_stopping(50, verbose=False)] # Tăng patience lên 50 cho an toàn\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04abfe99",
   "metadata": {
    "_cell_guid": "7be97632-4041-4c41-8843-b8c5f9e2e017",
    "_uuid": "b35a7267-d7a5-4c77-95ca-908b650de8a6",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-02T02:53:59.335879Z",
     "iopub.status.busy": "2025-12-02T02:53:59.335521Z",
     "iopub.status.idle": "2025-12-02T03:22:08.113648Z",
     "shell.execute_reply": "2025-12-02T03:22:08.112237Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1688.814046,
     "end_time": "2025-12-02T03:22:08.135093",
     "exception": false,
     "start_time": "2025-12-02T02:53:59.321047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "PROCESSING SAMPLE 0\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/1942722887.py:20: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "  pl.count().alias(f'item_total_counts{suffix}'),\n",
      "/tmp/ipykernel_13/1942722887.py:41: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "  pl.count().alias('session_length'),\n",
      "/tmp/ipykernel_13/1942722887.py:49: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "  pl.count().alias('num_repetitions'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing clicks ---\n",
      "  >> Performing Feature Selection for clicks...\n",
      "[LightGBM] [Info] Total groups: 462875, total data: 2000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.214096 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5953\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000000, number of used features: 38\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "     Selected 35 features. Top 5: ['source_history', 'recency_score', 'wgt_clicks', 'wgt_clicks_decayed', 'rank_clicks']\n",
      "  >> Training Final Model for clicks with 35 features...\n",
      "[LightGBM] [Info] Total groups: 516928, total data: 3501267\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.308321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5691\n",
      "[LightGBM] [Info] Number of data points in the train set: 3501267, number of used features: 35\n",
      "\n",
      "--- Processing carts ---\n",
      "  >> Performing Feature Selection for carts...\n",
      "[LightGBM] [Info] Total groups: 459338, total data: 1989456\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.198657 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5948\n",
      "[LightGBM] [Info] Number of data points in the train set: 1989456, number of used features: 38\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "     Selected 35 features. Top 5: ['session_length', 'rank_buys', 'rank_diff_buys_buy2buy', 'rank_diff_click_buy2buy', 'item_cart_counts_all']\n",
      "  >> Training Final Model for carts with 35 features...\n",
      "[LightGBM] [Info] Total groups: 459338, total data: 1989456\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.160273 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5934\n",
      "[LightGBM] [Info] Number of data points in the train set: 1989456, number of used features: 35\n",
      "\n",
      "--- Processing orders ---\n",
      "  >> Performing Feature Selection for orders...\n",
      "[LightGBM] [Info] Total groups: 383437, total data: 1147279\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.119507 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5951\n",
      "[LightGBM] [Info] Number of data points in the train set: 1147279, number of used features: 38\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "     Selected 35 features. Top 5: ['wgt_clicks', 'source_history', 'item_total_counts_all', 'rank_clicks', 'rank_buys']\n",
      "  >> Training Final Model for orders with 35 features...\n",
      "[LightGBM] [Info] Total groups: 383437, total data: 1147279\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.313673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5913\n",
      "[LightGBM] [Info] Number of data points in the train set: 1147279, number of used features: 35\n",
      "\n",
      "==============================\n",
      "PROCESSING SAMPLE 1\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/1942722887.py:20: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "  pl.count().alias(f'item_total_counts{suffix}'),\n",
      "/tmp/ipykernel_13/1942722887.py:41: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "  pl.count().alias('session_length'),\n",
      "/tmp/ipykernel_13/1942722887.py:49: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "  pl.count().alias('num_repetitions'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing clicks ---\n",
      "  >> Reusing selected features from Sample 0 for clicks\n",
      "  >> Training Final Model for clicks with 35 features...\n",
      "[LightGBM] [Info] Total groups: 516740, total data: 3498583\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.372291 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5696\n",
      "[LightGBM] [Info] Number of data points in the train set: 3498583, number of used features: 35\n",
      "\n",
      "--- Processing carts ---\n",
      "  >> Reusing selected features from Sample 0 for carts\n",
      "  >> Training Final Model for carts with 35 features...\n",
      "[LightGBM] [Info] Total groups: 458315, total data: 1984752\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.167808 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5931\n",
      "[LightGBM] [Info] Number of data points in the train set: 1984752, number of used features: 35\n",
      "\n",
      "--- Processing orders ---\n",
      "  >> Reusing selected features from Sample 0 for orders\n",
      "  >> Training Final Model for orders with 35 features...\n",
      "[LightGBM] [Info] Total groups: 381770, total data: 1142722\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.329391 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5913\n",
      "[LightGBM] [Info] Number of data points in the train set: 1142722, number of used features: 35\n",
      "\n",
      "==============================\n",
      "PROCESSING SAMPLE 2\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/1942722887.py:20: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "  pl.count().alias(f'item_total_counts{suffix}'),\n",
      "/tmp/ipykernel_13/1942722887.py:41: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "  pl.count().alias('session_length'),\n",
      "/tmp/ipykernel_13/1942722887.py:49: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "  pl.count().alias('num_repetitions'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing clicks ---\n",
      "  >> Reusing selected features from Sample 0 for clicks\n",
      "  >> Training Final Model for clicks with 35 features...\n",
      "[LightGBM] [Info] Total groups: 515740, total data: 3500442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.367729 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5690\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500442, number of used features: 35\n",
      "\n",
      "--- Processing carts ---\n",
      "  >> Reusing selected features from Sample 0 for carts\n",
      "  >> Training Final Model for carts with 35 features...\n",
      "[LightGBM] [Info] Total groups: 457486, total data: 1997289\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.144652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5925\n",
      "[LightGBM] [Info] Number of data points in the train set: 1997289, number of used features: 35\n",
      "\n",
      "--- Processing orders ---\n",
      "  >> Reusing selected features from Sample 0 for orders\n",
      "  >> Training Final Model for orders with 35 features...\n",
      "[LightGBM] [Info] Total groups: 380057, total data: 1143776\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.318871 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5915\n",
      "[LightGBM] [Info] Number of data points in the train set: 1143776, number of used features: 35\n",
      "\n",
      "All training finished!\n",
      "CPU times: user 1h 33min 19s, sys: 9min 12s, total: 1h 42min 31s\n",
      "Wall time: 28min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Dictionary để lưu danh sách feature tốt nhất cho mỗi loại (sẽ được điền ở vòng lặp 0)\n",
    "best_features_map = {} \n",
    "trained_models_lst = []\n",
    "\n",
    "# Giả sử history_source_dfs đã có sẵn từ các bước trước\n",
    "for i in range(len(seeds)):\n",
    "    print(f\"\\n{'='*30}\\nPROCESSING SAMPLE {i}\\n{'='*30}\")\n",
    "    \n",
    "    TEMP_CHUNK_PATH = f'/kaggle/working/temp_candidate_chunks/sample_{i}/'\n",
    "    \n",
    "    # 1. Chuẩn bị Features (Tĩnh & Động)\n",
    "    history_source_df = history_source_dfs[i]\n",
    "    \n",
    "    # Feature Tĩnh (Item) - Tính trên history_source_df (để tránh leak)\n",
    "    time_window_feats = [\n",
    "        create_time_window_features(history_source_df, None),\n",
    "        create_time_window_features(history_source_df, 7)\n",
    "    ]\n",
    "    \n",
    "    # Feature Động (Session) - Tính trên history_source_df\n",
    "    session_feats, interaction_feats, last_items = create_session_context_features(history_source_df)\n",
    "\n",
    "    # Dictionary lưu model của sample này\n",
    "    current_sample_models = {}\n",
    "\n",
    "    for pred_type in ['clicks', 'carts', 'orders']:\n",
    "        print(f\"\\n--- Processing {pred_type} ---\")\n",
    "        \n",
    "        # 2. Load dữ liệu thô (Candidate + Label)\n",
    "        df_train = pl.scan_parquet(TEMP_CHUNK_PATH + f'training_set_{pred_type}.pqt').collect()\n",
    "        \n",
    "        # 3. Thêm tất cả Features (Full set)\n",
    "        df_train = add_features(\n",
    "            df_train, \n",
    "            time_window_feats, \n",
    "            session_feats, \n",
    "            interaction_feats, \n",
    "            last_items\n",
    "        )\n",
    "        \n",
    "        # 4. Feature Selection (Chỉ chạy ở Sample đầu tiên)\n",
    "        if i == 0:\n",
    "            # Chọn top 50-60 feature tốt nhất cho loại dự đoán này\n",
    "            selected_feats = select_best_features(df_train, pred_type, top_k=35)\n",
    "            best_features_map[pred_type] = selected_feats\n",
    "        else:\n",
    "            print(f\"  >> Reusing selected features from Sample 0 for {pred_type}\")\n",
    "            \n",
    "        # 5. Huấn luyện Model Chính thức\n",
    "        # Chỉ dùng các feature đã được chọn trong best_features_map\n",
    "        final_feats = best_features_map[pred_type]\n",
    "        model = train_final_model(df_train, final_feats, pred_type)\n",
    "        \n",
    "        # Lưu model\n",
    "        model.booster_.save_model(TEMP_CHUNK_PATH + f'lgbm_ranker_{pred_type}_optimized.txt')\n",
    "        current_sample_models[pred_type] = model\n",
    "        \n",
    "        # Dọn dẹp RAM ngay lập tức\n",
    "        del df_train, model\n",
    "        gc.collect()\n",
    "\n",
    "    trained_models_lst.append(current_sample_models)\n",
    "    \n",
    "    # Dọn dẹp các biến feature lớn\n",
    "    del time_window_feats, session_feats, interaction_feats, last_items\n",
    "    gc.collect()\n",
    "\n",
    "print(\"\\nAll training finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f4c2fa1",
   "metadata": {
    "_cell_guid": "c9b7954e-f15f-466b-a1af-8d2f200de09d",
    "_uuid": "641a8ed8-5b9d-473c-8df6-546c13d5e9ec",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-02T03:22:08.175515Z",
     "iopub.status.busy": "2025-12-02T03:22:08.175129Z",
     "iopub.status.idle": "2025-12-02T03:22:08.363533Z",
     "shell.execute_reply": "2025-12-02T03:22:08.362595Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.212518,
     "end_time": "2025-12-02T03:22:08.366892",
     "exception": false,
     "start_time": "2025-12-02T03:22:08.154374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(seeds)):\n",
    "    TEMP_CHUNK_PATH = f'/kaggle/working/temp_candidate_chunks/sample_{i}/'\n",
    "    for pred_type in ['clicks', 'carts', 'orders']:\n",
    "        trained_models_lst[i][pred_type].booster_.save_model(TEMP_CHUNK_PATH + f'lgbm_ranker_{pred_type}.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c786556a",
   "metadata": {
    "_cell_guid": "42914314-d1bc-4fab-bb7b-7ba66fd079b5",
    "_uuid": "00d7a4d0-bb41-40d1-9bd1-83ff1c25b313",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.019616,
     "end_time": "2025-12-02T03:22:08.409362",
     "exception": false,
     "start_time": "2025-12-02T03:22:08.389746",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28bc08a1",
   "metadata": {
    "_cell_guid": "f750f32b-bb6f-484d-921e-b81ecbdf3efe",
    "_uuid": "d6224481-9537-427d-8bff-840b75d6e2da",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-02T03:22:08.448145Z",
     "iopub.status.busy": "2025-12-02T03:22:08.447827Z",
     "iopub.status.idle": "2025-12-02T03:22:47.313970Z",
     "shell.execute_reply": "2025-12-02T03:22:47.312943Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 38.90563,
     "end_time": "2025-12-02T03:22:47.333506",
     "exception": false,
     "start_time": "2025-12-02T03:22:08.427876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.8 s, sys: 51.4 s, total: 1min 25s\n",
      "Wall time: 38.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from src.pipeline.preprocess import *\n",
    "from src.core.utils import *\n",
    "# Load train parquet\n",
    "train_df = load_raw_data_parquet('/kaggle/input/otto-chunk-data-inparquet-format/train_parquet/*')\n",
    "# Load test parquet\n",
    "valid_df = load_raw_data_parquet('/kaggle/input/otto-chunk-data-inparquet-format/test_parquet/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84a3939d",
   "metadata": {
    "_cell_guid": "76e8c9d5-b83b-406f-90e5-08681dbe4e29",
    "_uuid": "6d321562-b953-4c9f-b7ba-c9c1fc0c423a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-02T03:22:47.372025Z",
     "iopub.status.busy": "2025-12-02T03:22:47.371673Z",
     "iopub.status.idle": "2025-12-02T03:23:13.275554Z",
     "shell.execute_reply": "2025-12-02T03:23:13.274302Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 25.925301,
     "end_time": "2025-12-02T03:23:13.277330",
     "exception": false,
     "start_time": "2025-12-02T03:22:47.352029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.5 s, sys: 9.76 s, total: 31.3 s\n",
      "Wall time: 25.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from src.candidate_generation.loader import *\n",
    "MATRIX_BASE_PATH = '/kaggle/input/otto-precal-covisit-matrices/submission/all/'\n",
    "\n",
    "df_clicks_valid = load_covisit_matrix(MATRIX_BASE_PATH + 'top_*_clicks_*.pqt', 'clicks', 20)\n",
    "df_buys_valid = load_covisit_matrix(MATRIX_BASE_PATH + 'top_*_carts_orders_*.pqt', 'buys', 15)\n",
    "df_buy2buy_valid = load_covisit_matrix(MATRIX_BASE_PATH + 'top_*_buy2buy_*.pqt', 'buy2buy', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dec402b2",
   "metadata": {
    "_cell_guid": "5d7c8177-f6b0-4731-b24d-a04718572c41",
    "_uuid": "e01b23e1-99c3-432d-8617-1b11ddc01ade",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-02T03:23:13.317589Z",
     "iopub.status.busy": "2025-12-02T03:23:13.317224Z",
     "iopub.status.idle": "2025-12-02T03:23:14.455932Z",
     "shell.execute_reply": "2025-12-02T03:23:14.454785Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.161329,
     "end_time": "2025-12-02T03:23:14.458166",
     "exception": false,
     "start_time": "2025-12-02T03:23:13.296837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "history_df = valid_df.select(['session', 'aid']).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c368ae6a",
   "metadata": {
    "_cell_guid": "ed89d19f-0fd4-4f4f-9574-9e4c5024f9c5",
    "_uuid": "c8b31e59-a9c4-4a05-9af1-c5585dc03aca",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-02T03:23:14.507457Z",
     "iopub.status.busy": "2025-12-02T03:23:14.506956Z",
     "iopub.status.idle": "2025-12-02T03:24:46.281794Z",
     "shell.execute_reply": "2025-12-02T03:24:46.280682Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 91.817434,
     "end_time": "2025-12-02T03:24:46.302921",
     "exception": false,
     "start_time": "2025-12-02T03:23:14.485487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 26s, sys: 28.9 s, total: 1min 55s\n",
      "Wall time: 1min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import polars as pl\n",
    "# Prepare global popular candidate\n",
    "top_clicks_popular = train_df.filter(pl.col('type') == 0)['aid'].value_counts().sort(['count'], descending=[True]).head(15)['aid']\n",
    "top_carts_popular = train_df.filter(pl.col('type') == 1)['aid'].value_counts().sort(['count'], descending=[True]).head(20)['aid']\n",
    "top_orders_popular = train_df.filter(pl.col('type') == 2)['aid'].value_counts().sort(['count'], descending=[True]).head(20)['aid']\n",
    "\n",
    "popular_items = pl.concat([top_clicks_popular, \n",
    "                           top_carts_popular, \n",
    "                           top_orders_popular]).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d2f0811",
   "metadata": {
    "_cell_guid": "ad174c58-42db-4ebe-a3ee-ca971b9dbd50",
    "_uuid": "73b3a9b7-4cd3-44a5-b4f9-0b38aa00f541",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-02T03:24:46.342645Z",
     "iopub.status.busy": "2025-12-02T03:24:46.342289Z",
     "iopub.status.idle": "2025-12-02T03:24:46.372758Z",
     "shell.execute_reply": "2025-12-02T03:24:46.371734Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.052328,
     "end_time": "2025-12-02T03:24:46.374266",
     "exception": false,
     "start_time": "2025-12-02T03:24:46.321938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (33, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>candidate_aid</th></tr><tr><td>i64</td></tr></thead><tbody><tr><td>29735</td></tr><tr><td>33343</td></tr><tr><td>108125</td></tr><tr><td>125278</td></tr><tr><td>152547</td></tr><tr><td>&hellip;</td></tr><tr><td>1502122</td></tr><tr><td>1562705</td></tr><tr><td>1603001</td></tr><tr><td>1629608</td></tr><tr><td>1733943</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (33, 1)\n",
       "┌───────────────┐\n",
       "│ candidate_aid │\n",
       "│ ---           │\n",
       "│ i64           │\n",
       "╞═══════════════╡\n",
       "│ 29735         │\n",
       "│ 33343         │\n",
       "│ 108125        │\n",
       "│ 125278        │\n",
       "│ 152547        │\n",
       "│ …             │\n",
       "│ 1502122       │\n",
       "│ 1562705       │\n",
       "│ 1603001       │\n",
       "│ 1629608       │\n",
       "│ 1733943       │\n",
       "└───────────────┘"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular_items_df = pl.DataFrame({'candidate_aid': popular_items})\n",
    "popular_items_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95918e7c",
   "metadata": {
    "_cell_guid": "0ba612a8-67e4-498d-a6fd-1f6984c9bc1b",
    "_uuid": "beec9c66-df89-4b21-9e3b-931fc41e47f7",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-02T03:24:46.414606Z",
     "iopub.status.busy": "2025-12-02T03:24:46.414222Z",
     "iopub.status.idle": "2025-12-02T03:25:52.823941Z",
     "shell.execute_reply": "2025-12-02T03:25:52.822884Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 66.43177,
     "end_time": "2025-12-02T03:25:52.825694",
     "exception": false,
     "start_time": "2025-12-02T03:24:46.393924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "item_popularity_df = pre_compute_item_popularity(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67724582",
   "metadata": {
    "_cell_guid": "c7ec733c-cc81-4d93-aa04-b572fce474fb",
    "_uuid": "b5e93b2a-9aa8-4a1d-924e-396f7e8e05f7",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-02T03:25:52.866626Z",
     "iopub.status.busy": "2025-12-02T03:25:52.866155Z",
     "iopub.status.idle": "2025-12-02T03:26:30.289389Z",
     "shell.execute_reply": "2025-12-02T03:26:30.286524Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 37.449582,
     "end_time": "2025-12-02T03:26:30.295226",
     "exception": false,
     "start_time": "2025-12-02T03:25:52.845644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/1942722887.py:20: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "  pl.count().alias(f'item_total_counts{suffix}'),\n",
      "/tmp/ipykernel_13/1942722887.py:41: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "  pl.count().alias('session_length'),\n",
      "/tmp/ipykernel_13/1942722887.py:49: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "  pl.count().alias('num_repetitions'),\n"
     ]
    }
   ],
   "source": [
    "time_window_feats = [\n",
    "    create_time_window_features(train_df, None),\n",
    "    create_time_window_features(train_df, 7)\n",
    "]\n",
    "session_feats, interaction_feats, last_items = create_session_context_features(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97cc1c13",
   "metadata": {
    "_cell_guid": "daa8bc99-2360-4961-b305-0b66348e3eb0",
    "_uuid": "4703b31f-07d4-492d-82c7-2af399c6ea44",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-02T03:26:30.396173Z",
     "iopub.status.busy": "2025-12-02T03:26:30.395547Z",
     "iopub.status.idle": "2025-12-02T07:13:56.840129Z",
     "shell.execute_reply": "2025-12-02T07:13:56.839044Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 13646.50607,
     "end_time": "2025-12-02T07:13:56.844178",
     "exception": false,
     "start_time": "2025-12-02T03:26:30.338108",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing 1671803 sessions in 31 chunks ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:00<?, ?it/s]/tmp/ipykernel_13/3029749649.py:53: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_before = feature_chunk.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/3029749649.py:138: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_after = feature_chunk_filtered.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chunk 0: Avg candidates Before=116.4, After=63.3\n",
      "  Chunk 0: Predicting scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/31 [07:36<3:48:13, 456.45s/it]/tmp/ipykernel_13/3029749649.py:53: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_before = feature_chunk.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/3029749649.py:138: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_after = feature_chunk_filtered.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chunk 1: Avg candidates Before=110.0, After=63.2\n",
      "  Chunk 1: Predicting scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 2/31 [15:21<3:43:00, 461.41s/it]/tmp/ipykernel_13/3029749649.py:53: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_before = feature_chunk.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/3029749649.py:138: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_after = feature_chunk_filtered.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chunk 2: Avg candidates Before=108.3, After=63.2\n",
      "  Chunk 2: Predicting scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 3/31 [22:44<3:31:31, 453.28s/it]/tmp/ipykernel_13/3029749649.py:53: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_before = feature_chunk.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/3029749649.py:138: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_after = feature_chunk_filtered.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chunk 3: Avg candidates Before=107.8, After=63.3\n",
      "  Chunk 3: Predicting scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/31 [30:10<3:22:36, 450.22s/it]/tmp/ipykernel_13/3029749649.py:53: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_before = feature_chunk.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/3029749649.py:138: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_after = feature_chunk_filtered.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chunk 4: Avg candidates Before=105.8, After=63.4\n",
      "  Chunk 4: Predicting scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 5/31 [37:42<3:15:20, 450.80s/it]/tmp/ipykernel_13/3029749649.py:53: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_before = feature_chunk.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/3029749649.py:138: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_after = feature_chunk_filtered.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chunk 5: Avg candidates Before=108.7, After=62.9\n",
      "  Chunk 5: Predicting scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 6/31 [45:20<3:08:56, 453.47s/it]/tmp/ipykernel_13/3029749649.py:53: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_before = feature_chunk.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/3029749649.py:138: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_after = feature_chunk_filtered.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chunk 6: Avg candidates Before=104.4, After=63.0\n",
      "  Chunk 6: Predicting scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/31 [52:36<2:58:59, 447.48s/it]/tmp/ipykernel_13/3029749649.py:53: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_before = feature_chunk.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/3029749649.py:138: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_after = feature_chunk_filtered.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chunk 7: Avg candidates Before=104.6, After=63.2\n",
      "  Chunk 7: Predicting scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 8/31 [59:55<2:50:31, 444.83s/it]/tmp/ipykernel_13/3029749649.py:53: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_before = feature_chunk.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/3029749649.py:138: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_after = feature_chunk_filtered.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chunk 8: Avg candidates Before=104.8, After=63.2\n",
      "  Chunk 8: Predicting scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 9/31 [1:07:13<2:42:20, 442.73s/it]/tmp/ipykernel_13/3029749649.py:53: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_before = feature_chunk.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/3029749649.py:138: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_after = feature_chunk_filtered.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chunk 9: Avg candidates Before=103.3, After=63.2\n",
      "  Chunk 9: Predicting scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 10/31 [1:14:27<2:33:58, 439.93s/it]/tmp/ipykernel_13/3029749649.py:53: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_before = feature_chunk.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/3029749649.py:138: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_after = feature_chunk_filtered.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chunk 10: Avg candidates Before=111.1, After=63.2\n",
      "  Chunk 10: Predicting scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 11/31 [1:21:52<2:27:12, 441.61s/it]/tmp/ipykernel_13/3029749649.py:53: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_before = feature_chunk.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/3029749649.py:138: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_after = feature_chunk_filtered.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chunk 11: Avg candidates Before=104.9, After=63.1\n",
      "  Chunk 11: Predicting scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 12/31 [1:29:12<2:19:42, 441.21s/it]/tmp/ipykernel_13/3029749649.py:53: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_before = feature_chunk.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/3029749649.py:138: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_after = feature_chunk_filtered.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chunk 12: Avg candidates Before=104.6, After=63.2\n",
      "  Chunk 12: Predicting scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 13/31 [1:36:47<2:13:33, 445.19s/it]/tmp/ipykernel_13/3029749649.py:53: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_before = feature_chunk.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/3029749649.py:138: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_after = feature_chunk_filtered.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chunk 13: Avg candidates Before=104.2, After=63.2\n",
      "  Chunk 13: Predicting scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 14/31 [1:44:20<2:06:52, 447.78s/it]/tmp/ipykernel_13/3029749649.py:53: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_before = feature_chunk.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/3029749649.py:138: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_after = feature_chunk_filtered.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chunk 14: Avg candidates Before=107.2, After=63.2\n",
      "  Chunk 14: Predicting scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 15/31 [1:52:07<2:00:57, 453.57s/it]/tmp/ipykernel_13/3029749649.py:53: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_before = feature_chunk.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/3029749649.py:138: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_after = feature_chunk_filtered.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chunk 15: Avg candidates Before=105.0, After=63.2\n",
      "  Chunk 15: Predicting scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 16/31 [1:59:49<1:53:59, 455.99s/it]/tmp/ipykernel_13/3029749649.py:53: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_before = feature_chunk.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/3029749649.py:138: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_after = feature_chunk_filtered.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chunk 16: Avg candidates Before=103.4, After=63.2\n",
      "  Chunk 16: Predicting scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 17/31 [2:07:09<1:45:14, 451.06s/it]/tmp/ipykernel_13/3029749649.py:53: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_before = feature_chunk.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/3029749649.py:138: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_after = feature_chunk_filtered.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chunk 17: Avg candidates Before=104.2, After=63.2\n",
      "  Chunk 17: Predicting scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 18/31 [2:14:40<1:37:43, 451.07s/it]/tmp/ipykernel_13/3029749649.py:53: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_before = feature_chunk.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/3029749649.py:138: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_after = feature_chunk_filtered.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chunk 18: Avg candidates Before=106.6, After=63.2\n",
      "  Chunk 18: Predicting scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 19/31 [2:22:01<1:29:38, 448.24s/it]/tmp/ipykernel_13/3029749649.py:53: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_before = feature_chunk.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/3029749649.py:138: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_after = feature_chunk_filtered.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chunk 19: Avg candidates Before=103.3, After=63.1\n",
      "  Chunk 19: Predicting scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 20/31 [2:29:39<1:22:41, 451.02s/it]/tmp/ipykernel_13/3029749649.py:53: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_before = feature_chunk.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/3029749649.py:138: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_after = feature_chunk_filtered.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chunk 20: Avg candidates Before=102.7, After=63.1\n",
      "  Chunk 20: Predicting scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 21/31 [2:37:09<1:15:07, 450.75s/it]/tmp/ipykernel_13/3029749649.py:53: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_before = feature_chunk.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/3029749649.py:138: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_after = feature_chunk_filtered.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chunk 21: Avg candidates Before=105.3, After=63.2\n",
      "  Chunk 21: Predicting scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 22/31 [2:44:54<1:08:14, 454.98s/it]/tmp/ipykernel_13/3029749649.py:53: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_before = feature_chunk.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/3029749649.py:138: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_after = feature_chunk_filtered.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chunk 22: Avg candidates Before=107.6, After=63.2\n",
      "  Chunk 22: Predicting scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 23/31 [2:53:05<1:02:06, 465.79s/it]/tmp/ipykernel_13/3029749649.py:53: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_before = feature_chunk.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/3029749649.py:138: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_after = feature_chunk_filtered.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chunk 23: Avg candidates Before=103.8, After=63.2\n",
      "  Chunk 23: Predicting scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 24/31 [3:00:57<54:34, 467.82s/it]  /tmp/ipykernel_13/3029749649.py:53: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_before = feature_chunk.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/3029749649.py:138: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_after = feature_chunk_filtered.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chunk 24: Avg candidates Before=103.3, After=63.2\n",
      "  Chunk 24: Predicting scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 25/31 [3:08:32<46:23, 463.90s/it]/tmp/ipykernel_13/3029749649.py:53: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_before = feature_chunk.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/3029749649.py:138: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_after = feature_chunk_filtered.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chunk 25: Avg candidates Before=105.4, After=63.3\n",
      "  Chunk 25: Predicting scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 26/31 [3:16:09<38:28, 461.80s/it]/tmp/ipykernel_13/3029749649.py:53: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_before = feature_chunk.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/3029749649.py:138: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_after = feature_chunk_filtered.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chunk 26: Avg candidates Before=104.1, After=63.2\n",
      "  Chunk 26: Predicting scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 27/31 [3:24:02<31:01, 465.27s/it]/tmp/ipykernel_13/3029749649.py:53: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_before = feature_chunk.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/3029749649.py:138: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_after = feature_chunk_filtered.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chunk 27: Avg candidates Before=101.7, After=63.1\n",
      "  Chunk 27: Predicting scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 28/31 [3:31:58<23:25, 468.52s/it]/tmp/ipykernel_13/3029749649.py:53: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_before = feature_chunk.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/3029749649.py:138: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_after = feature_chunk_filtered.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chunk 28: Avg candidates Before=98.9, After=63.1\n",
      "  Chunk 28: Predicting scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 29/31 [3:39:37<15:31, 465.52s/it]/tmp/ipykernel_13/3029749649.py:53: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_before = feature_chunk.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/3029749649.py:138: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_after = feature_chunk_filtered.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chunk 29: Avg candidates Before=96.8, After=63.2\n",
      "  Chunk 29: Predicting scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 30/31 [3:47:22<07:45, 465.33s/it]/tmp/ipykernel_13/3029749649.py:53: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_before = feature_chunk.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/3029749649.py:138: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  count_after = feature_chunk_filtered.group_by('session').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chunk 30: Avg candidates Before=62.7, After=60.8\n",
      "  Chunk 30: Predicting scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [3:47:25<00:00, 440.19s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "N_CHUNKS = 30\n",
    "\n",
    "all_sessions = history_df['session'].unique().to_list()\n",
    "chunk_size = len(all_sessions) // N_CHUNKS\n",
    "\n",
    "\n",
    "TEMP_PREDICTION_CHUNK_PATH = '/kaggle/working/temp_prediction_chunks/' # Thư mục để lưu các file tạm\n",
    "os.makedirs(TEMP_PREDICTION_CHUNK_PATH, exist_ok=True)\n",
    "\n",
    "stats_before_filtering = []\n",
    "stats_after_filtering = []\n",
    "\n",
    "W_HISTORY = 12.0\n",
    "W_REPETITION = 2.0\n",
    "W_BUY2BUY = 0.6\n",
    "W_BUYS = 0.3\n",
    "W_CLICKS = 0.2\n",
    "\n",
    "PRE_FILTER_TOP_K = 40\n",
    "PRE_FILTER_RANDOM_N = 25\n",
    "\n",
    "print(f\"\\n--- Processing {len(all_sessions)} sessions in {N_CHUNKS+1} chunks ---\")\n",
    "for i in tqdm(range(N_CHUNKS + 1)):\n",
    "    start = i * chunk_size\n",
    "    end = (i + 1) * chunk_size\n",
    "    if start >= len(all_sessions):\n",
    "        break\n",
    "    \n",
    "    session_chunk_ids = all_sessions[start:end]\n",
    "    history_chunk = history_df.filter(pl.col('session').is_in(session_chunk_ids))\n",
    "    \n",
    "    # Gọi hàm xử lý cho chunk\n",
    "    chunk_result = process_chunk(history_chunk, popular_items_df,\n",
    "                                 df_clicks_valid, df_buys_valid, df_buy2buy_valid)\n",
    "    # Thêm đặc trưng cuối cùng cho nguồn popular\n",
    "    chunk_result = chunk_result.with_columns(\n",
    "        pl.col('candidate_aid').is_in(popular_items_df['candidate_aid']).cast(pl.UInt8).alias('source_popular')\n",
    "    )\n",
    "    # --- B. THÊM FEATURE CHO CHUNK ---\n",
    "    feature_chunk = add_features(\n",
    "        chunk_result, \n",
    "        time_window_feats,\n",
    "        session_feats,\n",
    "        interaction_feats,\n",
    "        last_items,\n",
    "    )\n",
    "\n",
    "    # ===================================================================\n",
    "    # BƯỚC ĐO LƯỜNG #1: TRƯỚC KHI LỌC\n",
    "    # ===================================================================\n",
    "    # Tính số lượng ứng viên cho mỗi session trong chunk này\n",
    "    count_before = feature_chunk.group_by('session').count()\n",
    "    # Lấy giá trị trung bình và thêm vào list\n",
    "    avg_before = count_before['count'].mean()\n",
    "    if avg_before is not None:\n",
    "        stats_before_filtering.append(avg_before)\n",
    "\n",
    "    # ===================================================================\n",
    "    # BƯỚC PRE-FILTERING (Tăng tốc lgb.predict)\n",
    "    # ===================================================================\n",
    "    epsilon = 1e-9 # Để tránh chia cho 0\n",
    "    feature_chunk = feature_chunk.with_columns([\n",
    "        # Chuẩn hóa num_repetitions_in_session\n",
    "        (\n",
    "            (pl.col('num_repetitions') - pl.col('num_repetitions').min().over('session')) /\n",
    "            (pl.col('num_repetitions').max().over('session') - pl.col('num_repetitions').min().over('session') + epsilon)\n",
    "        ).alias('norm_repetition'),\n",
    "        \n",
    "        # Chuẩn hóa wgt_buy2buy\n",
    "        (\n",
    "            (pl.col('wgt_buy2buy') - pl.col('wgt_buy2buy').min().over('session')) /\n",
    "            (pl.col('wgt_buy2buy').max().over('session') - pl.col('wgt_buy2buy').min().over('session') + epsilon)\n",
    "        ).alias('norm_wgt_buy2buy'),\n",
    "        \n",
    "        # Chuẩn hóa wgt_buys\n",
    "        (\n",
    "            (pl.col('wgt_buys') - pl.col('wgt_buys').min().over('session')) /\n",
    "            (pl.col('wgt_buys').max().over('session') - pl.col('wgt_buys').min().over('session') + epsilon)\n",
    "        ).alias('norm_wgt_buys'),\n",
    "        \n",
    "        # Chuẩn hóa wgt_clicks\n",
    "        (\n",
    "            (pl.col('wgt_clicks') - pl.col('wgt_clicks').min().over('session')) /\n",
    "            (pl.col('wgt_clicks').max().over('session') - pl.col('wgt_clicks').min().over('session') + epsilon)\n",
    "        ).alias('norm_wgt_clicks'),\n",
    "    ]).fill_nan(0) # Điền 0 cho các trường hợp max == min\n",
    "    \n",
    "    # --- TÍNH TOÁN ĐIỂM SỐ HEURISTIC (Sử dụng các feature đã chuẩn hóa) ---\n",
    "    feature_chunk = feature_chunk.with_columns(\n",
    "        (\n",
    "            (pl.col('source_history') * W_HISTORY) +\n",
    "            (pl.col('norm_repetition') * W_REPETITION) +\n",
    "            (pl.col('norm_wgt_buy2buy') * W_BUY2BUY) +\n",
    "            (pl.col('norm_wgt_buys') * W_BUYS) +\n",
    "            (pl.col('norm_wgt_clicks') * W_CLICKS)\n",
    "        ).alias('heuristic_score')\n",
    "    )\n",
    "\n",
    "    print(feature_chunk.to_pandas().isna().sum().sum())\n",
    "    \n",
    "    \n",
    "    # --- Sắp xếp TOÀN BỘ chunk theo session và điểm heuristic ---\n",
    "    feature_chunk_sorted = feature_chunk.sort(['session', 'heuristic_score'], descending=[False, True])\n",
    "    \n",
    "    # --- Lấy Top K (Exploitation) ---\n",
    "    # .head() sẽ lấy các dòng đầu tiên (có điểm cao nhất) cho mỗi nhóm session\n",
    "    top_k_candidates = feature_chunk_sorted.group_by('session', maintain_order=True).head(PRE_FILTER_TOP_K)\n",
    "    \n",
    "    # --- Lấy Phần còn lại ---\n",
    "    # Dùng anti_join để tìm tất cả các ứng viên không thuộc top K\n",
    "    remaining_candidates = feature_chunk.join(\n",
    "        top_k_candidates.select(['session', 'candidate_aid']),\n",
    "        on=['session', 'candidate_aid'], \n",
    "        how='anti'\n",
    "    )\n",
    "    \n",
    "        # 1. Xáo trộn (shuffle) các dòng trong mỗi nhóm session\n",
    "    # 2. Lấy N dòng đầu tiên (.head(N)) từ mỗi nhóm đã được xáo trộn\n",
    "    random_candidates = remaining_candidates.select(\n",
    "        pl.all().shuffle().over('session')\n",
    "    ).group_by('session', maintain_order=True).head(PRE_FILTER_RANDOM_N)\n",
    "\n",
    "    \n",
    "    # --- Gộp 2 phần lại ---\n",
    "    feature_chunk_filtered = pl.concat([\n",
    "        top_k_candidates,\n",
    "        random_candidates\n",
    "    ])\n",
    "    \n",
    "    # Loại bỏ các cột tạm thời\n",
    "    cols_to_drop = [col for col in feature_chunk_filtered.columns if col.startswith('norm_') or col == 'heuristic_score']\n",
    "    feature_chunk_filtered = feature_chunk_filtered.drop(cols_to_drop)\n",
    "    \n",
    "    # ===================================================================\n",
    "    # BƯỚC ĐO LƯỜNG #2: SAU KHI LỌC\n",
    "    # ===================================================================\n",
    "    count_after = feature_chunk_filtered.group_by('session').count()\n",
    "    avg_after = count_after['count'].mean()\n",
    "    if avg_after is not None:\n",
    "        stats_after_filtering.append(avg_after)\n",
    "        \n",
    "    print(f\"  Chunk {i}: Avg candidates Before={avg_before:.1f}, After={avg_after:.1f}\")\n",
    "    \n",
    "    # --- C. DỰ ĐOÁN TRÊN CHUNK (BƯỚC MỚI) ---\n",
    "    print(f\"  Chunk {i}: Predicting scores...\")\n",
    "    \n",
    "    # Sắp xếp chunk theo session để đảm bảo thứ tự\n",
    "    feature_chunk_filtered = feature_chunk_filtered.sort('session')\n",
    "    \n",
    "    # List để lưu các mảng điểm số từ mỗi bộ model\n",
    "    all_scores = {'clicks': [], 'carts': [], 'orders': []}\n",
    "    \n",
    "    # Lặp qua 3 bộ model đã được tải\n",
    "    for model_type in ['clicks', 'carts', 'orders']:\n",
    "        # 1. Lấy danh sách feature chuẩn cho loại model này\n",
    "        # (Đây là danh sách đã được chọn lọc ở bước Feature Selection khi train)\n",
    "        selected_features = best_features_map[model_type]\n",
    "        \n",
    "        # 2. Tạo X_chunk CHỈ VỚI các feature này từ DataFrame\n",
    "        # Lưu ý: Phải select từ DataFrame, không phải từ numpy array tổng\n",
    "        X_chunk_for_type = feature_chunk_filtered.select(selected_features).to_numpy()\n",
    "        \n",
    "        # 3. Ensemble: Lặp qua các model trong list và dự đoán\n",
    "        for model_set in trained_models_lst:\n",
    "            model = model_set[model_type]\n",
    "            # Dự đoán và thêm vào list\n",
    "            pred = model.predict(X_chunk_for_type)\n",
    "            all_scores[model_type].append(pred)\n",
    "        \n",
    "    # Lấy trung bình các điểm số\n",
    "    avg_scores_clicks = np.mean(all_scores['clicks'], axis=0)\n",
    "    avg_scores_carts = np.mean(all_scores['carts'], axis=0)\n",
    "    avg_scores_orders = np.mean(all_scores['orders'], axis=0)\n",
    "    \n",
    "    # --- LOGIC ENSEMBLE KẾT THÚC ---\n",
    "    \n",
    "    # --- D. LƯU KẾT QUẢ ĐÃ THU GỌN ---\n",
    "    # Chỉ lưu các cột cần thiết cho việc xếp hạng cuối cùng\n",
    "    # --- D. LƯU KẾT QUẢ ĐÃ ĐƯỢC ENSEMBLE ---\n",
    "    prediction_chunk = feature_chunk_filtered.select(['session', 'candidate_aid']).with_columns([\n",
    "        pl.Series(\"score_clicks\", avg_scores_clicks),\n",
    "        pl.Series(\"score_carts\", avg_scores_carts),\n",
    "        pl.Series(\"score_orders\", avg_scores_orders)\n",
    "    ])\n",
    "    \n",
    "    # Lưu chunk kết quả dự đoán ra đĩa\n",
    "    prediction_chunk.write_parquet(TEMP_PREDICTION_CHUNK_PATH + f'predictions_chunk_{i}.pqt')\n",
    "    \n",
    "    del chunk_result, feature_chunk, X_chunk_for_type, prediction_chunk, feature_chunk_filtered\n",
    "        \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b43c82e",
   "metadata": {
    "_cell_guid": "c57f89a9-6149-4229-8613-a32eae1125ae",
    "_uuid": "7b83efe8-a1f2-497e-b85f-c15914045a40",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-02T07:13:56.936151Z",
     "iopub.status.busy": "2025-12-02T07:13:56.935787Z",
     "iopub.status.idle": "2025-12-02T07:13:57.288297Z",
     "shell.execute_reply": "2025-12-02T07:13:57.287269Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.40464,
     "end_time": "2025-12-02T07:13:57.290107",
     "exception": false,
     "start_time": "2025-12-02T07:13:56.885467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del df_clicks_valid, df_buys_valid, df_buy2buy_valid, popular_items_df\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af60cbfa",
   "metadata": {
    "_cell_guid": "e919f720-9828-42c8-bce4-2399ebd70e24",
    "_uuid": "fa0af6d4-ac92-4176-81f1-b07358af4cfd",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-02T07:13:57.347031Z",
     "iopub.status.busy": "2025-12-02T07:13:57.346669Z",
     "iopub.status.idle": "2025-12-02T07:14:06.294776Z",
     "shell.execute_reply": "2025-12-02T07:14:06.293507Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 8.97893,
     "end_time": "2025-12-02T07:14:06.296859",
     "exception": false,
     "start_time": "2025-12-02T07:13:57.317929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Aggregating all prediction chunks ---\n",
      "Aggregated predictions DataFrame shape: (105628733, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Aggregating all prediction chunks ---\")\n",
    "TEMP_PREDICTION_CHUNK_PATH = '/kaggle/working/temp_prediction_chunks/'\n",
    "\n",
    "# Sử dụng scan_parquet để đọc tất cả các file chunk một cách \"lười biếng\"\n",
    "lazy_predictions_df = pl.scan_parquet(TEMP_PREDICTION_CHUNK_PATH + 'predictions_chunk_*.pqt')\n",
    "\n",
    "# .collect() để hiện thực hóa DataFrame. Bước này bây giờ rất nhanh và nhẹ.\n",
    "predictions_df = lazy_predictions_df.collect()\n",
    "\n",
    "print(f\"Aggregated predictions DataFrame shape: {predictions_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99c690a8",
   "metadata": {
    "_cell_guid": "66e56b1d-ded2-4ae2-8fbe-918036c0bd9b",
    "_uuid": "ef4d052c-53a7-4411-ba26-8afa8ed2728c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-02T07:14:06.358594Z",
     "iopub.status.busy": "2025-12-02T07:14:06.358195Z",
     "iopub.status.idle": "2025-12-02T07:16:29.359129Z",
     "shell.execute_reply": "2025-12-02T07:16:29.357800Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 143.035172,
     "end_time": "2025-12-02T07:16:29.361464",
     "exception": false,
     "start_time": "2025-12-02T07:14:06.326292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ranking candidates and creating separate prediction dataframes ---\n",
      "Saving submission.csv...\n",
      "Submission file created successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>session_type</th><th>labels</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;13245763_clicks&quot;</td><td>&quot;1564562 1353965 1174319 127018…</td></tr><tr><td>&quot;13810206_clicks&quot;</td><td>&quot;1776643 889222 114709 1406660 …</td></tr><tr><td>&quot;13773565_clicks&quot;</td><td>&quot;168507 1141500 594728 1739065 …</td></tr><tr><td>&quot;13779704_clicks&quot;</td><td>&quot;323291 1070279 1330138 1708158…</td></tr><tr><td>&quot;13730564_clicks&quot;</td><td>&quot;659680 1645990 1695413 1403918…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌─────────────────┬─────────────────────────────────┐\n",
       "│ session_type    ┆ labels                          │\n",
       "│ ---             ┆ ---                             │\n",
       "│ str             ┆ str                             │\n",
       "╞═════════════════╪═════════════════════════════════╡\n",
       "│ 13245763_clicks ┆ 1564562 1353965 1174319 127018… │\n",
       "│ 13810206_clicks ┆ 1776643 889222 114709 1406660 … │\n",
       "│ 13773565_clicks ┆ 168507 1141500 594728 1739065 … │\n",
       "│ 13779704_clicks ┆ 323291 1070279 1330138 1708158… │\n",
       "│ 13730564_clicks ┆ 659680 1645990 1695413 1403918… │\n",
       "└─────────────────┴─────────────────────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n--- Ranking candidates and creating separate prediction dataframes ---\")\n",
    "\n",
    "# Dictionary để lưu kết quả cuối cùng\n",
    "final_predictions = {}\n",
    "\n",
    "for model_type in ['clicks', 'carts', 'orders']:\n",
    "    \n",
    "    score_col = f'score_{model_type}'\n",
    "    preds_for_type = predictions_df.select(['session', 'candidate_aid', score_col])\n",
    "    \n",
    "    # Sắp xếp và lấy top 20\n",
    "    top_20_preds = preds_for_type.sort(score_col, descending=True) \\\n",
    "                                 .group_by('session', maintain_order=False) \\\n",
    "                                 .head(20) \\\n",
    "                                 .group_by('session', maintain_order=True) \\\n",
    "                                 .agg(pl.col('candidate_aid').alias('labels'))\n",
    "    \n",
    "    final_predictions[model_type] = top_20_preds\n",
    "\n",
    "# --- BƯỚC 1 & 2 (Không đổi) ---\n",
    "pred_df_clicks = final_predictions['clicks'].with_columns(pl.col('session').cast(pl.Utf8) + \"_clicks\")\n",
    "pred_df_carts = final_predictions['carts'].with_columns(pl.col('session').cast(pl.Utf8) + \"_carts\")\n",
    "pred_df_orders = final_predictions['orders'].with_columns(pl.col('session').cast(pl.Utf8) + \"_orders\")\n",
    "\n",
    "submission_df = pl.concat([\n",
    "    pred_df_clicks,\n",
    "    pred_df_carts,\n",
    "    pred_df_orders\n",
    "]).rename({'session': 'session_type'})\n",
    "\n",
    "# --- BƯỚC 3: CHUYỂN ĐỔI LIST THÀNH CHUỖI (ĐÃ SỬA LỖI) ---\n",
    "submission_df = submission_df.with_columns(\n",
    "    # 1. Áp dụng `cast(pl.Utf8)` cho TỪNG PHẦN TỬ bên trong list\n",
    "    pl.col('labels').list.eval(pl.element().cast(pl.Utf8))\n",
    "    # 2. Bây giờ mới JOIN các chuỗi đó lại\n",
    "    .list.join(\" \")\n",
    ")\n",
    "\n",
    "# --- BƯỚC 4: LƯU RA FILE CSV (Không đổi) ---\n",
    "print(\"Saving submission.csv...\")\n",
    "submission_df.write_csv(\"/kaggle/working/submission.csv\")\n",
    "\n",
    "print(\"Submission file created successfully!\")\n",
    "display(submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37878b9e",
   "metadata": {
    "_cell_guid": "13d56ee0-7361-4e41-973b-0937023fe580",
    "_uuid": "5ec86ec9-1497-4151-9c0c-d6a3699339fa",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.031774,
     "end_time": "2025-12-02T07:16:29.425910",
     "exception": false,
     "start_time": "2025-12-02T07:16:29.394136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 2597726,
     "sourceId": 4436180,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2623568,
     "sourceId": 4483558,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8384420,
     "sourceId": 13274305,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8770990,
     "sourceId": 13819184,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8876655,
     "sourceId": 13929603,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17335.785938,
   "end_time": "2025-12-02T07:16:33.561975",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-02T02:27:37.776037",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
